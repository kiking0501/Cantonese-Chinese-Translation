{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "COLAB_Train_Cantonese_BERT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiking0501/Cantonese-Chinese-Translation/blob/master/code/v2/COLAB_Train_Cantonese_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDSkPs5FcNOa",
        "colab_type": "text"
      },
      "source": [
        "# **An Example to Train Cantonese-BERT**\n",
        "\n",
        "- Below is designed to be run in Colab Jupyter Environment with a GCS bucket. If you are unsure about this, check <a href=\"https://medium.com/fenwicks/tutorial-0-setting-up-google-colab-tpu-runtime-and-cloud-storage-b88d34aa9dcb\" target=\"_blank\">here</a>.\n",
        "\n",
        "- To resume training after a disconnection, run only cells with <!>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WsKOLeNIQpy",
        "colab_type": "text"
      },
      "source": [
        "## **<!>Specify Tensorflow 1.X version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0pA-gQG9Hl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC5rjpfId63f",
        "colab_type": "text"
      },
      "source": [
        "## **<!>Setup GCS bucket name**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE2YN_zQeP2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUCKET_NAME = \"bert_cantonese\" #@param {type:\"string\"}\n",
        "BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0FqRDukIY41",
        "colab_type": "text"
      },
      "source": [
        "## **<!>Authorize to GCS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "auth.authenticate_user()\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I554Ij67IHER",
        "colab_type": "text"
      },
      "source": [
        "## **Download Bert**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNaqcWom6tYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/google-research/bert\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umY9iZotfZ6K",
        "colab_type": "text"
      },
      "source": [
        "### **Or, if you have a customized BERT folder in GCS bucket**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSGq12okfZc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil -m cp -r $BUCKET_PATH/code/v2/bert ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAjHvqKigiVq",
        "colab_type": "text"
      },
      "source": [
        "## **Download Wikipedia Data, WikiExtractor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIbVjaS86tYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DUMP_FILE = zh_yuewiki-20200301-pages-articles-multistream.xml.bz2\n",
        "!wget https://dumps.wikimedia.org/zh_yuewiki/20200301/$DUMP_FILE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mADPr9SvAvbe",
        "colab_type": "code",
        "outputId": "2bc2e28b-b816-44ca-a4aa-e580bdbad714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "!wget https://github.com/attardi/wikiextractor/archive/master.zip\n",
        "!unzip master.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-20 22:15:07--  https://github.com/attardi/wikiextractor/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/attardi/wikiextractor/zip/master [following]\n",
            "--2020-03-20 22:15:07--  https://codeload.github.com/attardi/wikiextractor/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [ <=>                ] 249.29K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-20 22:15:08 (2.37 MB/s) - ‘master.zip’ saved [255270]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BA5VUPrhYds",
        "colab_type": "text"
      },
      "source": [
        "## **Extract Wiki Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gw79bY4A-U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python wikiextractor-master/WikiExtractor.py -o . --json -b 500k zh_yuewiki-20200301-pages-articles-multistream.xml.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMSnZt4FBKjZ",
        "colab_type": "code",
        "outputId": "262dd9dc-9cfa-4f63-f66c-82f82caf707d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "!ls ./AA"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wiki_00  wiki_11  wiki_22  wiki_33  wiki_44  wiki_55  wiki_66  wiki_77\twiki_88\n",
            "wiki_01  wiki_12  wiki_23  wiki_34  wiki_45  wiki_56  wiki_67  wiki_78\twiki_89\n",
            "wiki_02  wiki_13  wiki_24  wiki_35  wiki_46  wiki_57  wiki_68  wiki_79\twiki_90\n",
            "wiki_03  wiki_14  wiki_25  wiki_36  wiki_47  wiki_58  wiki_69  wiki_80\twiki_91\n",
            "wiki_04  wiki_15  wiki_26  wiki_37  wiki_48  wiki_59  wiki_70  wiki_81\twiki_92\n",
            "wiki_05  wiki_16  wiki_27  wiki_38  wiki_49  wiki_60  wiki_71  wiki_82\twiki_93\n",
            "wiki_06  wiki_17  wiki_28  wiki_39  wiki_50  wiki_61  wiki_72  wiki_83\twiki_94\n",
            "wiki_07  wiki_18  wiki_29  wiki_40  wiki_51  wiki_62  wiki_73  wiki_84\twiki_95\n",
            "wiki_08  wiki_19  wiki_30  wiki_41  wiki_52  wiki_63  wiki_74  wiki_85\twiki_96\n",
            "wiki_09  wiki_20  wiki_31  wiki_42  wiki_53  wiki_64  wiki_75  wiki_86\n",
            "wiki_10  wiki_21  wiki_32  wiki_43  wiki_54  wiki_65  wiki_76  wiki_87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blKAr5jcEbIY",
        "colab_type": "code",
        "outputId": "426cb5fd-5f6d-477d-b673-21e30c21127e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "!mv ./AA ./json\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json    sample_data\n",
            "bert\t    wikiextractor-master\n",
            "json\t    zh_yuewiki-20200301-pages-articles-multistream.xml.bz2\n",
            "master.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JfYq5mUio9u",
        "colab_type": "text"
      },
      "source": [
        "## **Save Clean Wiki Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU-otlIEFCfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import re\n",
        "import jieba\n",
        "\n",
        "DATA_PATH = \".\"\n",
        "WIKI_PATH = DATA_PATH\n",
        "WIKI_ORI_PATH = os.path.join(DATA_PATH, \"json\")\n",
        "\n",
        "def read_wiki(file_name):\n",
        "    data = []\n",
        "    with open(os.path.join(WIKI_ORI_PATH, file_name), 'r') as f:\n",
        "        for json_obj in f:\n",
        "            data.append(json.loads(json_obj))\n",
        "    return data\n",
        "\n",
        "\n",
        "def save_clean_wiki(file_name, verbose=True):\n",
        "    json_list = read_wiki(file_name)\n",
        "    for json_obj in json_list:\n",
        "        output_path = os.path.join(\".\", \"clean\", \"%s_%s\" % (json_obj['id'], json_obj['title'].replace('/', '-').strip()))\n",
        "        with open(output_path, \"w\") as f:\n",
        "            for line in json_obj['text'].split('\\n'):\n",
        "                content = re.findall('\\（.*?\\）', line)\n",
        "\n",
        "                for l in line.split('。'):\n",
        "                    if l:\n",
        "                        f.write(' '.join(jieba.cut(l, cut_all=False)) + ' 。\\n')\n",
        "        print(\"%s saved.\" % output_path)\n",
        "\n",
        "\n",
        "def read_clean_wiki(file_code):\n",
        "    with open(os.path.join(WIKI_PATH, \"clean\", file_code)) as f:\n",
        "        return [l.strip().split(' ') for l in f]\n",
        "\n",
        "\n",
        "def save_clean_wikipedia(output_file=\"wiki_yue_overview.csv\", verbose=True):\n",
        "    load_jieba()\n",
        "    for (_, _, filenames) in sorted(os.walk(WIKI_ORI_PATH)):\n",
        "        for file_name in sorted(filenames):\n",
        "            save_clean_wiki(file_name)\n",
        "    total = 0\n",
        "    with open(os.path.join(WIKI_PATH, output_file), \"w\") as f:\n",
        "        file_codes = []\n",
        "        for (_, _, filenames) in os.walk(os.path.join(\".\", \"clean\")):\n",
        "            file_codes.extend(filenames)\n",
        "        for ind, code in enumerate(sorted(file_codes)):\n",
        "            f.write('%s,%s\\n' % (ind, code))\n",
        "        total += len(file_codes)\n",
        "    if verbose:\n",
        "        print(\"Total: %d. %s saved.\" % (total, output_file))\n",
        "\n",
        "\n",
        "def read_clean_wikipedia(overview_csv=\"wiki_yue_overview.csv\"):\n",
        "    with open(os.path.join(WIKI_PATH, overview_csv)) as f:\n",
        "        for line in f.readlines():\n",
        "            # print(line)\n",
        "            _, file_code = line.partition(',')[0], line.partition(',')[2].strip()\n",
        "            if file_code.startswith('wiki'):\n",
        "                continue\n",
        "            # print(\"Reading %s..\" % file_code)\n",
        "            for sen in read_clean_wiki(file_code):\n",
        "                yield sen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQI0F6giuB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir clean\n",
        "save_clean_wikipedia()\n",
        "\n",
        "output_path = \"wiki_dataset.txt\"\n",
        "with open(output_path, \"w\") as f:\n",
        "    for ind, sen in enumerate(read_clean_wikipedia()):\n",
        "        f.write(\"%s\\n\" % \" \".join(sen))\n",
        "    print(\"%s saved.\" % f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSLg61KOWkc7",
        "colab_type": "text"
      },
      "source": [
        "## **Create Vocab Files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klUVyx8MWxES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp $GCS/data/embedding/cantonese/custom_wiki.bin ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny-AGrlP6tZf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "model = KeyedVectors.load_word2vec_format(\"./custom_wiki.bin\", binary=True)\n",
        "print(model.index2word[:1000])\n",
        "\n",
        "bert_vocab = model.index2word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM3Hbay26tZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
        "bert_vocab = ctrl_symbols + bert_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seNfGT-T6tZv",
        "colab_type": "code",
        "outputId": "5eb86faf-363e-4369-998c-0080f715127b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
        "print(len(bert_vocab))\n",
        "VOC_SIZE = len(bert_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "70035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvnhPgXE6tZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68B08VEB6taH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head -n 50 $VOC_FNAME"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gactQSD26tad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testcase = \"香港士巴拿係一種架生，作用係方便上緊或者扭鬆正方形同六角形嘅螺絲頭同螺絲帽，手柄畀人揸住用力。\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_Un3vxTy6tap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "bert_tokenizer.tokenize(testcase)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gA4tAWeQbmb7",
        "colab_type": "text"
      },
      "source": [
        "## **Create Local Shard, Generate PreTraining Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-6ZAeJY6tax",
        "colab_type": "code",
        "outputId": "e9cf0b7f-f1d0-4180-8371-9cf02bad0427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d $PRC_DATA_FPATH ./shards/shard_\n",
        "!ls ./shards/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shard_0000  shard_0001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bip2_BO6tbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
        "PROCESSES = 8 #@param {type:\"integer\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r_45IS76tbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XARGS_CMD = (\"ls ./shards/ | \"\n",
        "             \"xargs -n 1 -P {} -I{} \"\n",
        "             \"python3 bert/create_pretraining_data.py \"\n",
        "             \"--input_file=./shards/{} \"\n",
        "             \"--output_file={}/{}.tfrecord \"\n",
        "             \"--vocab_file={} \"\n",
        "             \"--do_lower_case={} \"\n",
        "             \"--max_predictions_per_seq={} \"\n",
        "             \"--max_seq_length={} \"\n",
        "             \"--masked_lm_prob={} \"\n",
        "             \"--random_seed=34 \"\n",
        "             \"--dupe_factor=5\")\n",
        "\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
        "                             VOC_FNAME, DO_LOWER_CASE, \n",
        "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcwdZ-AV6tbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.gfile.MkDir(PRETRAINING_DIR)\n",
        "!$XARGS_CMD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXGEw7vbb2X-",
        "colab_type": "text"
      },
      "source": [
        "### **Or, if you already have PreTraining Data from GCS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWBO-9qEb_LJ",
        "colab_type": "code",
        "outputId": "0f3d3138-618e-48f1-899f-8b8cd106b09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!gsutil -m cp -r $GCS/code/v2/$PRETRAINING_DIR ."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CommandException: No URLs matched: /code/v2/\n",
            "CommandException: 1 file/object could not be transferred.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIbrgZlacRxb",
        "colab_type": "text"
      },
      "source": [
        "## **Create Trained Model Directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGNlx1aB6tba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n",
        "tf.gfile.MkDir(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzWpy1ZZ6tbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use this for BERT-base\n",
        "\n",
        "bert_base_config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1, \n",
        "  \"directionality\": \"bidi\", \n",
        "  \"hidden_act\": \"gelu\", \n",
        "  \"hidden_dropout_prob\": 0.1, \n",
        "  \"hidden_size\": 768, \n",
        "  \"initializer_range\": 0.02, \n",
        "  \"intermediate_size\": 3072, \n",
        "  \"max_position_embeddings\": 512, \n",
        "  \"num_attention_heads\": 12, \n",
        "  \"num_hidden_layers\": 12, \n",
        "  \"pooler_fc_size\": 768, \n",
        "  \"pooler_num_attention_heads\": 12, \n",
        "  \"pooler_num_fc_layers\": 3, \n",
        "  \"pooler_size_per_head\": 128, \n",
        "  \"pooler_type\": \"first_token_transform\", \n",
        "  \"type_vocab_size\": 2, \n",
        "  \"vocab_size\": VOC_SIZE\n",
        "}\n",
        "\n",
        "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
        "  json.dump(bert_base_config, fo, indent=2)\n",
        "  \n",
        "with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx4eCuxulspF",
        "colab_type": "text"
      },
      "source": [
        "### **Backup Directories to GCS Bucket: PreTraining Data and Trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qhs_TmY6tbp",
        "colab_type": "code",
        "outputId": "9e066689-d0bd-4c13-bb8b-65c57c670379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "!gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://bert_model/vocab.txt [Content-Type=text/plain]...\n",
            "Copying file://bert_model/bert_config.json [Content-Type=application/json]...\n",
            "Copying file://pretraining_data/shard_0001.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://pretraining_data/shard_0000.tfrecord [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "|\n",
            "Operation completed over 4 objects/530.5 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd9bShbic2Bq",
        "colab_type": "text"
      },
      "source": [
        "## **<!> Set Training Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0wJL1vv6tbx",
        "colab_type": "code",
        "outputId": "6a7565dd-133c-4c5d-feb6-4072d1241b39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import os\n",
        "\n",
        "BUCKET_NAME = \"bert_cantonese\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}\n",
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "# Input data pipeline config\n",
        "TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "\n",
        "# Training procedure config\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_STEPS = 1000000 #@param {type:\"integer\"}\n",
        "SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  BUCKET_PATH = \".\"\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-21 02:12:18,351 :  From /content/bert/modeling.py:93: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "2020-03-21 02:12:18,497 :  Using checkpoint: gs://bert_cantonese/bert_model/model.ckpt-28500\n",
            "2020-03-21 02:12:18,498 :  Using 2 data shards\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKh7mQ9u6tb5",
        "colab_type": "code",
        "outputId": "37c96a54-2ea5-4417-d603-523b8c42db72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=TRAIN_STEPS,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=BERT_GCS_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "  \n",
        "train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-21 02:12:26,362 :  Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f3d7eb56f28>) includes params argument, but params are not passed to Estimator.\n",
            "2020-03-21 02:12:26,364 :  Using config: {'_model_dir': 'gs://bert_cantonese/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.7.192.10:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3d7eb23f60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.7.192.10:8470', '_evaluation_master': 'grpc://10.7.192.10:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2500, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f3d7eb23748>}\n",
            "2020-03-21 02:12:26,365 :  _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ped7NlkB6tcC",
        "colab_type": "code",
        "outputId": "3b219df8-632a-4a2e-ff67-6d94a85574a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-03-21 02:12:29,257 :  Querying Tensorflow master (grpc://10.7.192.10:8470) for TPU system metadata.\n",
            "2020-03-21 02:12:29,278 :  Found TPU system:\n",
            "2020-03-21 02:12:29,279 :  *** Num TPU Cores: 8\n",
            "2020-03-21 02:12:29,280 :  *** Num TPU Workers: 1\n",
            "2020-03-21 02:12:29,280 :  *** Num TPU Cores Per Worker: 8\n",
            "2020-03-21 02:12:29,281 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 18073774665154168877)\n",
            "2020-03-21 02:12:29,283 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17709391651440839388)\n",
            "2020-03-21 02:12:29,284 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5318324718595205416)\n",
            "2020-03-21 02:12:29,284 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4836610270761407413)\n",
            "2020-03-21 02:12:29,286 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11358172445265626448)\n",
            "2020-03-21 02:12:29,286 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 17385798886852026940)\n",
            "2020-03-21 02:12:29,287 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 14077837964427228701)\n",
            "2020-03-21 02:12:29,288 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 14744382814188212921)\n",
            "2020-03-21 02:12:29,289 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14263942240975314199)\n",
            "2020-03-21 02:12:29,290 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 7544906316908012894)\n",
            "2020-03-21 02:12:29,291 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 615672901726125094)\n",
            "2020-03-21 02:12:29,300 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2020-03-21 02:12:29,301 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2020-03-21 02:12:29,320 :  Calling model_fn.\n",
            "2020-03-21 02:12:29,322 :  From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2020-03-21 02:12:29,332 :  From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "2020-03-21 02:12:29,333 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2020-03-21 02:12:29,367 :  From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2020-03-21 02:12:29,368 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2020-03-21 02:12:29,431 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2020-03-21 02:12:29,542 :  From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2020-03-21 02:12:29,581 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,585 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,589 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,593 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,596 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,600 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,603 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,607 :  Found small feature: next_sentence_labels [16, 1]\n",
            "2020-03-21 02:12:29,647 :  From /content/bert/run_pretraining.py:117: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "2020-03-21 02:12:29,648 :  *** Features ***\n",
            "2020-03-21 02:12:29,649 :    name = input_ids, shape = (16, 128)\n",
            "2020-03-21 02:12:29,651 :    name = input_mask, shape = (16, 128)\n",
            "2020-03-21 02:12:29,652 :    name = masked_lm_ids, shape = (16, 20)\n",
            "2020-03-21 02:12:29,652 :    name = masked_lm_positions, shape = (16, 20)\n",
            "2020-03-21 02:12:29,654 :    name = masked_lm_weights, shape = (16, 20)\n",
            "2020-03-21 02:12:29,654 :    name = next_sentence_labels, shape = (16, 1)\n",
            "2020-03-21 02:12:29,655 :    name = segment_ids, shape = (16, 128)\n",
            "2020-03-21 02:12:29,657 :  From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2020-03-21 02:12:29,661 :  From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2020-03-21 02:12:29,711 :  From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2020-03-21 02:12:29,762 :  From bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2020-03-21 02:12:29,789 :  From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2020-03-21 02:12:29,792 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2020-03-21 02:12:32,518 :  From /content/bert/run_pretraining.py:150: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "2020-03-21 02:12:33,000 :  **** Trainable Variables ****\n",
            "2020-03-21 02:12:33,001 :    name = bert/embeddings/word_embeddings:0, shape = (70035, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,002 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,003 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,004 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,005 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,005 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,006 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,007 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,008 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,009 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,010 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,011 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,012 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,012 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,013 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,014 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,015 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,016 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,016 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,017 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,018 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,019 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,020 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,020 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,021 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,022 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,023 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,024 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,025 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,025 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,026 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,027 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,028 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,029 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,030 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,031 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,031 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,032 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,033 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,034 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,035 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,036 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,037 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,037 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,038 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,039 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,040 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,041 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,042 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,043 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,043 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,044 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,045 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,046 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,047 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,048 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,049 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,049 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,050 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,051 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,052 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,053 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,054 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,055 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,056 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,056 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,057 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,058 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,059 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,060 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,061 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,062 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,063 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,063 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,064 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,065 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,066 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,067 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,068 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,069 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,069 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,070 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,071 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,072 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,073 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,074 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,075 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,075 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,076 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,077 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,078 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,079 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,080 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,081 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,082 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,082 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,083 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,084 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,085 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,086 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,087 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,088 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,088 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,089 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,090 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,091 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,092 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,093 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,094 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,095 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,095 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,096 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,097 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,098 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,098 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,099 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,099 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,100 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,101 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,101 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,102 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,103 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,104 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,105 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,105 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,106 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,107 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,108 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,109 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,109 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,110 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,111 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,112 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,113 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,114 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,115 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,116 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,116 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,117 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,118 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,119 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,120 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,120 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,121 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,122 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,123 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,124 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,125 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,126 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,126 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,127 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,128 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,129 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,130 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,131 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,132 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,132 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,134 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,134 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,135 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,136 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,137 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,138 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,139 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,140 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,141 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,142 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,143 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,144 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,145 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,146 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,147 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,148 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,149 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,150 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,151 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,152 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,153 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,154 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,155 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,156 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,156 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,157 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,158 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,159 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,160 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,161 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,162 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,163 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,163 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,164 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,165 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,166 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,167 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,168 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,169 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,170 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,170 :    name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,171 :    name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,172 :    name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,173 :    name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,174 :    name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,175 :    name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,176 :    name = cls/predictions/output_bias:0, shape = (70035,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,177 :    name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,180 :    name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
            "2020-03-21 02:12:33,181 :  From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2020-03-21 02:12:33,185 :  From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "2020-03-21 02:12:33,842 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2020-03-21 02:12:43,711 :  From /content/bert/run_pretraining.py:160: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "2020-03-21 02:12:45,093 :  From /content/bert/run_pretraining.py:161: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
            "\n",
            "2020-03-21 02:12:46,109 :  Create CheckpointSaverHook.\n",
            "2020-03-21 02:12:46,457 :  Done calling model_fn.\n",
            "2020-03-21 02:12:48,698 :  TPU job name worker\n",
            "2020-03-21 02:12:50,174 :  Graph was finalized.\n",
            "2020-03-21 02:12:50,314 :  Restoring parameters from gs://bert_cantonese/bert_model/model.ckpt-28500\n",
            "2020-03-21 02:13:12,332 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "2020-03-21 02:13:13,817 :  Running local_init_op.\n",
            "2020-03-21 02:13:14,551 :  Done running local_init_op.\n",
            "2020-03-21 02:13:22,910 :  Saving checkpoints for 28500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:13:45,367 :  From /tensorflow-1.15.0/python3.6/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2020-03-21 02:13:46,851 :  Initialized dataset iterators in 0 seconds\n",
            "2020-03-21 02:13:46,852 :  Installing graceful shutdown hook.\n",
            "2020-03-21 02:13:46,859 :  Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2020-03-21 02:13:46,863 :  Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2020-03-21 02:13:46,868 :  Init TPU system\n",
            "2020-03-21 02:13:51,387 :  Initialized TPU in 4 seconds\n",
            "2020-03-21 02:13:51,388 :  Starting infeed thread controller.\n",
            "2020-03-21 02:13:51,393 :  Starting outfeed thread controller.\n",
            "2020-03-21 02:13:52,123 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:13:52,124 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:14:30,952 :  Outfeed finished for iteration (0, 0)\n",
            "2020-03-21 02:15:31,041 :  Outfeed finished for iteration (0, 475)\n",
            "2020-03-21 02:16:31,132 :  Outfeed finished for iteration (0, 950)\n",
            "2020-03-21 02:17:31,223 :  Outfeed finished for iteration (0, 1425)\n",
            "2020-03-21 02:18:31,314 :  Outfeed finished for iteration (0, 1900)\n",
            "2020-03-21 02:19:31,403 :  Outfeed finished for iteration (0, 2375)\n",
            "2020-03-21 02:19:48,204 :  Saving checkpoints for 31000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:20:06,791 :  From /tensorflow-1.15.0/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2020-03-21 02:20:09,756 :  loss = 3.2700696, step = 31000\n",
            "2020-03-21 02:20:09,759 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:20:09,761 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:20:31,498 :  Outfeed finished for iteration (1, 123)\n",
            "2020-03-21 02:21:31,586 :  Outfeed finished for iteration (1, 598)\n",
            "2020-03-21 02:22:31,673 :  Outfeed finished for iteration (1, 1073)\n",
            "2020-03-21 02:23:31,760 :  Outfeed finished for iteration (1, 1548)\n",
            "2020-03-21 02:24:31,847 :  Outfeed finished for iteration (1, 2023)\n",
            "2020-03-21 02:25:31,934 :  Outfeed finished for iteration (1, 2498)\n",
            "2020-03-21 02:25:33,139 :  Saving checkpoints for 33500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:25:54,284 :  loss = 3.338607, step = 33500 (344.529 sec)\n",
            "2020-03-21 02:25:54,288 :  global_step/sec: 7.25629\n",
            "2020-03-21 02:25:54,292 :  examples/sec: 928.805\n",
            "2020-03-21 02:25:54,294 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:25:54,295 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:26:32,023 :  Outfeed finished for iteration (2, 286)\n",
            "2020-03-21 02:27:32,108 :  Outfeed finished for iteration (2, 761)\n",
            "2020-03-21 02:28:32,193 :  Outfeed finished for iteration (2, 1236)\n",
            "2020-03-21 02:29:32,277 :  Outfeed finished for iteration (2, 1711)\n",
            "2020-03-21 02:30:32,361 :  Outfeed finished for iteration (2, 2186)\n",
            "2020-03-21 02:31:13,034 :  Saving checkpoints for 36000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:31:34,343 :  loss = 3.1322317, step = 36000 (340.058 sec)\n",
            "2020-03-21 02:31:34,347 :  global_step/sec: 7.35164\n",
            "2020-03-21 02:31:34,350 :  examples/sec: 941.01\n",
            "2020-03-21 02:31:34,356 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:31:34,357 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:31:35,860 :  Outfeed finished for iteration (3, 0)\n",
            "2020-03-21 02:32:35,951 :  Outfeed finished for iteration (3, 475)\n",
            "2020-03-21 02:33:36,044 :  Outfeed finished for iteration (3, 950)\n",
            "2020-03-21 02:34:36,134 :  Outfeed finished for iteration (3, 1425)\n",
            "2020-03-21 02:35:36,226 :  Outfeed finished for iteration (3, 1900)\n",
            "2020-03-21 02:36:36,317 :  Outfeed finished for iteration (3, 2375)\n",
            "2020-03-21 02:36:53,071 :  Saving checkpoints for 38500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:37:21,055 :  loss = 3.128134, step = 38500 (346.712 sec)\n",
            "2020-03-21 02:37:21,059 :  global_step/sec: 7.2106\n",
            "2020-03-21 02:37:21,060 :  examples/sec: 922.957\n",
            "2020-03-21 02:37:21,063 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:37:21,064 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:37:36,435 :  Outfeed finished for iteration (4, 109)\n",
            "2020-03-21 02:38:36,517 :  Outfeed finished for iteration (4, 584)\n",
            "2020-03-21 02:39:36,600 :  Outfeed finished for iteration (4, 1059)\n",
            "2020-03-21 02:40:36,682 :  Outfeed finished for iteration (4, 1534)\n",
            "2020-03-21 02:41:36,765 :  Outfeed finished for iteration (4, 2009)\n",
            "2020-03-21 02:42:36,847 :  Outfeed finished for iteration (4, 2484)\n",
            "2020-03-21 02:42:39,839 :  Saving checkpoints for 41000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:43:02,872 :  loss = 2.5867982, step = 41000 (341.817 sec)\n",
            "2020-03-21 02:43:02,875 :  global_step/sec: 7.31388\n",
            "2020-03-21 02:43:02,878 :  examples/sec: 936.177\n",
            "2020-03-21 02:43:02,880 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:43:02,881 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:43:36,848 :  Outfeed finished for iteration (5, 256)\n",
            "2020-03-21 02:44:36,942 :  Outfeed finished for iteration (5, 731)\n",
            "2020-03-21 02:45:37,036 :  Outfeed finished for iteration (5, 1206)\n",
            "2020-03-21 02:46:37,130 :  Outfeed finished for iteration (5, 1681)\n",
            "2020-03-21 02:47:37,225 :  Outfeed finished for iteration (5, 2156)\n",
            "2020-03-21 02:48:21,683 :  Saving checkpoints for 43500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:48:46,878 :  loss = 3.0959535, step = 43500 (344.006 sec)\n",
            "2020-03-21 02:48:46,882 :  global_step/sec: 7.26729\n",
            "2020-03-21 02:48:46,885 :  examples/sec: 930.213\n",
            "2020-03-21 02:48:46,888 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:48:46,891 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:48:48,466 :  Outfeed finished for iteration (6, 0)\n",
            "2020-03-21 02:49:48,558 :  Outfeed finished for iteration (6, 475)\n",
            "2020-03-21 02:50:48,651 :  Outfeed finished for iteration (6, 950)\n",
            "2020-03-21 02:51:48,743 :  Outfeed finished for iteration (6, 1425)\n",
            "2020-03-21 02:52:48,836 :  Outfeed finished for iteration (6, 1900)\n",
            "2020-03-21 02:53:48,927 :  Outfeed finished for iteration (6, 2375)\n",
            "2020-03-21 02:54:05,692 :  Saving checkpoints for 46000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 02:54:27,072 :  loss = 3.020841, step = 46000 (340.194 sec)\n",
            "2020-03-21 02:54:27,075 :  global_step/sec: 7.34878\n",
            "2020-03-21 02:54:27,077 :  examples/sec: 940.644\n",
            "2020-03-21 02:54:27,080 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 02:54:27,081 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 02:54:48,943 :  Outfeed finished for iteration (7, 160)\n",
            "2020-03-21 02:55:49,032 :  Outfeed finished for iteration (7, 635)\n",
            "2020-03-21 02:56:49,121 :  Outfeed finished for iteration (7, 1110)\n",
            "2020-03-21 02:57:49,210 :  Outfeed finished for iteration (7, 1585)\n",
            "2020-03-21 02:58:49,298 :  Outfeed finished for iteration (7, 2060)\n",
            "2020-03-21 02:59:45,900 :  Saving checkpoints for 48500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:00:09,114 :  loss = 2.489214, step = 48500 (342.042 sec)\n",
            "2020-03-21 03:00:09,116 :  global_step/sec: 7.30906\n",
            "2020-03-21 03:00:09,120 :  examples/sec: 935.559\n",
            "2020-03-21 03:00:09,123 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:00:09,125 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:00:10,728 :  Outfeed finished for iteration (8, 0)\n",
            "2020-03-21 03:01:10,806 :  Outfeed finished for iteration (8, 475)\n",
            "2020-03-21 03:02:10,887 :  Outfeed finished for iteration (8, 950)\n",
            "2020-03-21 03:03:10,969 :  Outfeed finished for iteration (8, 1425)\n",
            "2020-03-21 03:04:11,050 :  Outfeed finished for iteration (8, 1900)\n",
            "2020-03-21 03:05:11,132 :  Outfeed finished for iteration (8, 2375)\n",
            "2020-03-21 03:05:27,926 :  Saving checkpoints for 51000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:05:50,599 :  loss = 1.9115465, step = 51000 (341.486 sec)\n",
            "2020-03-21 03:05:50,603 :  global_step/sec: 7.32093\n",
            "2020-03-21 03:05:50,605 :  examples/sec: 937.079\n",
            "2020-03-21 03:05:50,611 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:05:50,612 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:06:11,134 :  Outfeed finished for iteration (9, 149)\n",
            "2020-03-21 03:07:11,234 :  Outfeed finished for iteration (9, 624)\n",
            "2020-03-21 03:08:11,333 :  Outfeed finished for iteration (9, 1099)\n",
            "2020-03-21 03:09:11,434 :  Outfeed finished for iteration (9, 1574)\n",
            "2020-03-21 03:10:11,535 :  Outfeed finished for iteration (9, 2049)\n",
            "2020-03-21 03:11:09,514 :  Saving checkpoints for 53500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:11:32,761 :  loss = 2.2203298, step = 53500 (342.162 sec)\n",
            "2020-03-21 03:11:32,765 :  global_step/sec: 7.30648\n",
            "2020-03-21 03:11:32,766 :  examples/sec: 935.23\n",
            "2020-03-21 03:11:32,769 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:11:32,770 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:11:34,374 :  Outfeed finished for iteration (10, 0)\n",
            "2020-03-21 03:12:34,456 :  Outfeed finished for iteration (10, 475)\n",
            "2020-03-21 03:13:34,544 :  Outfeed finished for iteration (10, 950)\n",
            "2020-03-21 03:14:34,632 :  Outfeed finished for iteration (10, 1425)\n",
            "2020-03-21 03:15:34,719 :  Outfeed finished for iteration (10, 1900)\n",
            "2020-03-21 03:16:34,806 :  Outfeed finished for iteration (10, 2375)\n",
            "2020-03-21 03:16:51,549 :  Saving checkpoints for 56000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:17:17,829 :  loss = 2.2376184, step = 56000 (345.068 sec)\n",
            "2020-03-21 03:17:17,832 :  global_step/sec: 7.24497\n",
            "2020-03-21 03:17:17,834 :  examples/sec: 927.356\n",
            "2020-03-21 03:17:17,839 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:17:17,840 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:17:34,872 :  Outfeed finished for iteration (11, 122)\n",
            "2020-03-21 03:18:34,960 :  Outfeed finished for iteration (11, 597)\n",
            "2020-03-21 03:19:35,048 :  Outfeed finished for iteration (11, 1072)\n",
            "2020-03-21 03:20:35,134 :  Outfeed finished for iteration (11, 1547)\n",
            "2020-03-21 03:21:35,222 :  Outfeed finished for iteration (11, 2022)\n",
            "2020-03-21 03:22:35,309 :  Outfeed finished for iteration (11, 2497)\n",
            "2020-03-21 03:22:36,617 :  Saving checkpoints for 58500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:22:57,288 :  loss = 2.6766076, step = 58500 (339.459 sec)\n",
            "2020-03-21 03:22:57,292 :  global_step/sec: 7.36464\n",
            "2020-03-21 03:22:57,295 :  examples/sec: 942.673\n",
            "2020-03-21 03:22:57,299 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:22:57,300 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:23:35,333 :  Outfeed finished for iteration (12, 288)\n",
            "2020-03-21 03:24:35,417 :  Outfeed finished for iteration (12, 763)\n",
            "2020-03-21 03:25:35,501 :  Outfeed finished for iteration (12, 1238)\n",
            "2020-03-21 03:26:35,584 :  Outfeed finished for iteration (12, 1713)\n",
            "2020-03-21 03:27:35,668 :  Outfeed finished for iteration (12, 2188)\n",
            "2020-03-21 03:28:16,102 :  Saving checkpoints for 61000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:28:37,303 :  loss = 2.4711716, step = 61000 (340.014 sec)\n",
            "2020-03-21 03:28:37,305 :  global_step/sec: 7.35265\n",
            "2020-03-21 03:28:37,309 :  examples/sec: 941.14\n",
            "2020-03-21 03:28:37,313 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:28:37,318 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:28:38,930 :  Outfeed finished for iteration (13, 0)\n",
            "2020-03-21 03:29:39,015 :  Outfeed finished for iteration (13, 475)\n",
            "2020-03-21 03:30:39,100 :  Outfeed finished for iteration (13, 950)\n",
            "2020-03-21 03:31:39,186 :  Outfeed finished for iteration (13, 1425)\n",
            "2020-03-21 03:32:39,271 :  Outfeed finished for iteration (13, 1900)\n",
            "2020-03-21 03:33:39,356 :  Outfeed finished for iteration (13, 2375)\n",
            "2020-03-21 03:33:56,097 :  Saving checkpoints for 63500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:34:18,464 :  loss = 2.2258444, step = 63500 (341.161 sec)\n",
            "2020-03-21 03:34:18,467 :  global_step/sec: 7.3279\n",
            "2020-03-21 03:34:18,470 :  examples/sec: 937.971\n",
            "2020-03-21 03:34:18,476 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:34:18,477 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:34:39,415 :  Outfeed finished for iteration (14, 153)\n",
            "2020-03-21 03:35:39,506 :  Outfeed finished for iteration (14, 628)\n",
            "2020-03-21 03:36:39,596 :  Outfeed finished for iteration (14, 1103)\n",
            "2020-03-21 03:37:39,688 :  Outfeed finished for iteration (14, 1578)\n",
            "2020-03-21 03:38:39,778 :  Outfeed finished for iteration (14, 2053)\n",
            "2020-03-21 03:39:37,314 :  Saving checkpoints for 66000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:39:59,379 :  loss = 1.9303937, step = 66000 (340.915 sec)\n",
            "2020-03-21 03:39:59,382 :  global_step/sec: 7.3332\n",
            "2020-03-21 03:39:59,386 :  examples/sec: 938.65\n",
            "2020-03-21 03:39:59,389 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:39:59,390 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:40:00,949 :  Outfeed finished for iteration (15, 0)\n",
            "2020-03-21 03:41:01,069 :  Outfeed finished for iteration (15, 475)\n",
            "2020-03-21 03:42:01,189 :  Outfeed finished for iteration (15, 950)\n",
            "2020-03-21 03:43:01,309 :  Outfeed finished for iteration (15, 1425)\n",
            "2020-03-21 03:44:01,429 :  Outfeed finished for iteration (15, 1900)\n",
            "2020-03-21 03:45:01,550 :  Outfeed finished for iteration (15, 2375)\n",
            "2020-03-21 03:45:18,332 :  Saving checkpoints for 68500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:45:43,442 :  loss = 2.532034, step = 68500 (344.063 sec)\n",
            "2020-03-21 03:45:43,446 :  global_step/sec: 7.26609\n",
            "2020-03-21 03:45:43,448 :  examples/sec: 930.059\n",
            "2020-03-21 03:45:43,450 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:45:43,451 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:46:01,636 :  Outfeed finished for iteration (16, 131)\n",
            "2020-03-21 03:47:01,739 :  Outfeed finished for iteration (16, 606)\n",
            "2020-03-21 03:48:01,841 :  Outfeed finished for iteration (16, 1081)\n",
            "2020-03-21 03:49:01,945 :  Outfeed finished for iteration (16, 1556)\n",
            "2020-03-21 03:50:02,047 :  Outfeed finished for iteration (16, 2031)\n",
            "2020-03-21 03:51:02,306 :  Saving checkpoints for 71000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:51:22,816 :  loss = 1.6557885, step = 71000 (339.374 sec)\n",
            "2020-03-21 03:51:22,821 :  global_step/sec: 7.36649\n",
            "2020-03-21 03:51:22,823 :  examples/sec: 942.911\n",
            "2020-03-21 03:51:22,830 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:51:22,832 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:51:24,434 :  Outfeed finished for iteration (17, 0)\n",
            "2020-03-21 03:52:24,518 :  Outfeed finished for iteration (17, 475)\n",
            "2020-03-21 03:53:24,602 :  Outfeed finished for iteration (17, 950)\n",
            "2020-03-21 03:54:24,685 :  Outfeed finished for iteration (17, 1425)\n",
            "2020-03-21 03:55:24,769 :  Outfeed finished for iteration (17, 1900)\n",
            "2020-03-21 03:56:24,853 :  Outfeed finished for iteration (17, 2375)\n",
            "2020-03-21 03:56:41,601 :  Saving checkpoints for 73500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 03:57:02,042 :  loss = 2.4246395, step = 73500 (339.226 sec)\n",
            "2020-03-21 03:57:02,045 :  global_step/sec: 7.36976\n",
            "2020-03-21 03:57:02,046 :  examples/sec: 943.329\n",
            "2020-03-21 03:57:02,048 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 03:57:02,050 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 03:57:24,977 :  Outfeed finished for iteration (18, 168)\n",
            "2020-03-21 03:58:25,056 :  Outfeed finished for iteration (18, 643)\n",
            "2020-03-21 03:59:25,136 :  Outfeed finished for iteration (18, 1118)\n",
            "2020-03-21 04:00:25,215 :  Outfeed finished for iteration (18, 1593)\n",
            "2020-03-21 04:01:25,295 :  Outfeed finished for iteration (18, 2068)\n",
            "2020-03-21 04:02:20,849 :  Saving checkpoints for 76000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:02:46,293 :  loss = 1.9050466, step = 76000 (344.251 sec)\n",
            "2020-03-21 04:02:46,296 :  global_step/sec: 7.26214\n",
            "2020-03-21 04:02:46,299 :  examples/sec: 929.554\n",
            "2020-03-21 04:02:46,303 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:02:46,307 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:02:48,071 :  Outfeed finished for iteration (19, 0)\n",
            "2020-03-21 04:03:48,167 :  Outfeed finished for iteration (19, 475)\n",
            "2020-03-21 04:04:48,265 :  Outfeed finished for iteration (19, 950)\n",
            "2020-03-21 04:05:48,362 :  Outfeed finished for iteration (19, 1425)\n",
            "2020-03-21 04:06:48,460 :  Outfeed finished for iteration (19, 1900)\n",
            "2020-03-21 04:07:48,557 :  Outfeed finished for iteration (19, 2375)\n",
            "2020-03-21 04:08:05,370 :  Saving checkpoints for 78500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:08:28,634 :  loss = 1.979916, step = 78500 (342.340 sec)\n",
            "2020-03-21 04:08:28,637 :  global_step/sec: 7.30266\n",
            "2020-03-21 04:08:28,639 :  examples/sec: 934.74\n",
            "2020-03-21 04:08:28,643 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:08:28,644 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:08:48,582 :  Outfeed finished for iteration (20, 144)\n",
            "2020-03-21 04:09:48,673 :  Outfeed finished for iteration (20, 619)\n",
            "2020-03-21 04:10:48,765 :  Outfeed finished for iteration (20, 1094)\n",
            "2020-03-21 04:11:48,856 :  Outfeed finished for iteration (20, 1569)\n",
            "2020-03-21 04:12:48,948 :  Outfeed finished for iteration (20, 2044)\n",
            "2020-03-21 04:13:47,605 :  Saving checkpoints for 81000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:14:09,967 :  loss = 1.612743, step = 81000 (341.334 sec)\n",
            "2020-03-21 04:14:09,971 :  global_step/sec: 7.32422\n",
            "2020-03-21 04:14:09,972 :  examples/sec: 937.501\n",
            "2020-03-21 04:14:09,977 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:14:09,979 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:14:11,591 :  Outfeed finished for iteration (21, 0)\n",
            "2020-03-21 04:15:11,676 :  Outfeed finished for iteration (21, 475)\n",
            "2020-03-21 04:16:11,764 :  Outfeed finished for iteration (21, 950)\n",
            "2020-03-21 04:17:11,849 :  Outfeed finished for iteration (21, 1425)\n",
            "2020-03-21 04:18:11,936 :  Outfeed finished for iteration (21, 1900)\n",
            "2020-03-21 04:19:12,023 :  Outfeed finished for iteration (21, 2375)\n",
            "2020-03-21 04:19:28,774 :  Saving checkpoints for 83500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:19:50,144 :  loss = 2.1125355, step = 83500 (340.177 sec)\n",
            "2020-03-21 04:19:50,148 :  global_step/sec: 7.3491\n",
            "2020-03-21 04:19:50,150 :  examples/sec: 940.684\n",
            "2020-03-21 04:19:50,155 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:19:50,156 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:20:12,139 :  Outfeed finished for iteration (22, 161)\n",
            "2020-03-21 04:21:12,228 :  Outfeed finished for iteration (22, 636)\n",
            "2020-03-21 04:22:12,318 :  Outfeed finished for iteration (22, 1111)\n",
            "2020-03-21 04:23:12,409 :  Outfeed finished for iteration (22, 1586)\n",
            "2020-03-21 04:24:12,499 :  Outfeed finished for iteration (22, 2061)\n",
            "2020-03-21 04:25:08,979 :  Saving checkpoints for 86000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:25:40,768 :  loss = 2.2113562, step = 86000 (350.624 sec)\n",
            "2020-03-21 04:25:40,773 :  global_step/sec: 7.13016\n",
            "2020-03-21 04:25:40,774 :  examples/sec: 912.661\n",
            "2020-03-21 04:25:40,776 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:25:40,778 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:25:42,402 :  Outfeed finished for iteration (23, 0)\n",
            "2020-03-21 04:26:42,516 :  Outfeed finished for iteration (23, 475)\n",
            "2020-03-21 04:27:42,633 :  Outfeed finished for iteration (23, 950)\n",
            "2020-03-21 04:28:42,746 :  Outfeed finished for iteration (23, 1425)\n",
            "2020-03-21 04:29:42,860 :  Outfeed finished for iteration (23, 1900)\n",
            "2020-03-21 04:30:42,974 :  Outfeed finished for iteration (23, 2375)\n",
            "2020-03-21 04:30:59,756 :  Saving checkpoints for 88500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:31:31,476 :  loss = 2.0673153, step = 88500 (350.708 sec)\n",
            "2020-03-21 04:31:31,480 :  global_step/sec: 7.12843\n",
            "2020-03-21 04:31:31,482 :  examples/sec: 912.438\n",
            "2020-03-21 04:31:31,487 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:31:31,489 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:31:43,001 :  Outfeed finished for iteration (24, 78)\n",
            "2020-03-21 04:32:43,086 :  Outfeed finished for iteration (24, 553)\n",
            "2020-03-21 04:33:43,170 :  Outfeed finished for iteration (24, 1028)\n",
            "2020-03-21 04:34:43,253 :  Outfeed finished for iteration (24, 1503)\n",
            "2020-03-21 04:35:43,336 :  Outfeed finished for iteration (24, 1978)\n",
            "2020-03-21 04:36:43,419 :  Outfeed finished for iteration (24, 2453)\n",
            "2020-03-21 04:36:50,311 :  Saving checkpoints for 91000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:37:35,281 :  loss = 1.8464215, step = 91000 (363.805 sec)\n",
            "2020-03-21 04:37:35,283 :  global_step/sec: 6.87184\n",
            "2020-03-21 04:37:35,286 :  examples/sec: 879.595\n",
            "2020-03-21 04:37:35,289 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:37:35,290 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:37:43,479 :  Outfeed finished for iteration (25, 52)\n",
            "2020-03-21 04:38:43,570 :  Outfeed finished for iteration (25, 527)\n",
            "2020-03-21 04:39:43,660 :  Outfeed finished for iteration (25, 1002)\n",
            "2020-03-21 04:40:43,749 :  Outfeed finished for iteration (25, 1477)\n",
            "2020-03-21 04:41:43,840 :  Outfeed finished for iteration (25, 1952)\n",
            "2020-03-21 04:42:43,936 :  Outfeed finished for iteration (25, 2427)\n",
            "2020-03-21 04:42:54,131 :  Saving checkpoints for 93500 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:43:17,544 :  loss = 2.23246, step = 93500 (342.263 sec)\n",
            "2020-03-21 04:43:17,547 :  global_step/sec: 7.30431\n",
            "2020-03-21 04:43:17,549 :  examples/sec: 934.952\n",
            "2020-03-21 04:43:17,553 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:43:17,555 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:43:43,975 :  Outfeed finished for iteration (26, 196)\n",
            "2020-03-21 04:44:44,069 :  Outfeed finished for iteration (26, 671)\n",
            "2020-03-21 04:45:44,164 :  Outfeed finished for iteration (26, 1146)\n",
            "2020-03-21 04:46:44,259 :  Outfeed finished for iteration (26, 1621)\n",
            "2020-03-21 04:47:44,354 :  Outfeed finished for iteration (26, 2096)\n",
            "2020-03-21 04:48:36,418 :  Saving checkpoints for 96000 into gs://bert_cantonese/bert_model/model.ckpt.\n",
            "2020-03-21 04:49:00,341 :  loss = 2.4698257, step = 96000 (342.796 sec)\n",
            "2020-03-21 04:49:00,344 :  global_step/sec: 7.29294\n",
            "2020-03-21 04:49:00,350 :  examples/sec: 933.497\n",
            "2020-03-21 04:49:00,357 :  Enqueue next (2500) batch(es) of data to infeed.\n",
            "2020-03-21 04:49:00,360 :  Dequeue next (2500) batch(es) of data from outfeed.\n",
            "2020-03-21 04:49:01,970 :  Outfeed finished for iteration (27, 0)\n",
            "2020-03-21 04:50:02,060 :  Outfeed finished for iteration (27, 475)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXXEUPRy6tcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}